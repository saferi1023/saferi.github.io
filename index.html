<!DOCTYPE html>
<html lang="en" class="scroll-smooth dark">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Mohammed Saferi Rahman</title>
  <meta name="description" content="Personal website for a Computer Science PhD student ‚Äî research, publications, projects, teaching, and CV." />
  <meta name="keywords" content="Computer Science, HCI, Ubiquitous Computing, PhD, Research, Publications, Projects" />
  <meta name="author" content="Mohammed Saferi Rahman" />
  <!-- Open Graph -->
  <meta property="og:title" content="Mohammed Saferi Rahman" />
  <meta property="og:description" content="Research in HCI & Ubiquitous Computing. Publications, projects, and CV." />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="/assets/og-image.png" />
  <meta property="og:url" content="https://saferi1023.github.io/" />
  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Mohammed Saferi Rahman" />
  <meta name="twitter:description" content="Research in HCI & Ubiquitous Computing." />
  <meta name="twitter:image" content="/assets/og-image.png" />
  <link rel="icon" href="/assets/favicon.ico" />
  <meta name="theme-color" id="metaThemeColor" content="#0a0a0a" />
  <!-- Tailwind Play CDN (no build step needed) -->
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    // Tailwind config: custom colors & fonts
    tailwind.config = {
      darkMode: "class",
      theme: {
        extend: {
          colors: {
            brand: {
              50: '#fff7ed',
              100: '#ffedd5',
              200: '#fed7aa',
              300: '#fdba74',
              400: '#fb923c',
              500: '#f97316', // primary accent (orange)
              600: '#ea580c',
              700: '#c2410c',
              800: '#9a3412',
              900: '#7c2d12'
            }
          },
          fontFamily: {
            display: ['Inter', 'ui-sans-serif', 'system-ui', 'Segoe UI', 'Roboto', 'Helvetica', 'Arial', 'Apple Color Emoji', 'Segoe UI Emoji'],
            body: ['Inter', 'ui-sans-serif', 'system-ui']
          },
          boxShadow: {
            mellow: '0 10px 30px rgba(0,0,0,0.08)'
          }
        }
      }
    }
  </script>
  <!-- Inter font -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet" />
  <style>
    /* Prevent FOUC for theme */
    html { visibility: hidden; }
  </style>
  <script>
    // Apply saved theme before paint (default = dark)
    (function(){
      const saved = localStorage.getItem('theme'); // 'dark' | 'light' | null
      if (saved === 'light') {
        document.documentElement.classList.remove('dark');
      } else {
        document.documentElement.classList.add('dark'); // default to dark
      }
      document.documentElement.style.visibility = 'visible';
    })();
  </script>
</head>

<script>
(() => {
  let activeModal = null, lastFocused = null;

  const getFocusable = (root) =>
    Array.from(root.querySelectorAll('a[href], button:not([disabled]), textarea, input, select, [tabindex]:not([tabindex="-1"])'))
      .filter(el => el.offsetParent !== null);

  const openModal = (id) => {
    const m = document.getElementById(id);
    if (!m) return;
    lastFocused = document.activeElement;
    m.classList.remove('hidden'); m.classList.add('flex');
    document.body.classList.add('overflow-hidden');
    activeModal = m;
    const focusTarget = m.querySelector('[data-autofocus]') || getFocusable(m)[0];
    if (focusTarget) focusTarget.focus();
    // Default tab active
    const firstTab = m.querySelector('[data-tab]') || m.querySelector('.tab-btn');
    if (firstTab) firstTab.click();
  };

  const closeModal = () => {
    if (!activeModal) return;
    activeModal.classList.add('hidden'); activeModal.classList.remove('flex');
    document.body.classList.remove('overflow-hidden');
    if (lastFocused) lastFocused.focus();
    activeModal = null;
  };

  // Open/close
  document.addEventListener('click', (e) => {
    const openBtn = e.target.closest('[data-modal-open]');
    if (openBtn) { e.preventDefault(); openModal(openBtn.getAttribute('data-modal-open')); return; }
    if (e.target.closest('[data-modal-close]')) { e.preventDefault(); closeModal(); return; }
    if (activeModal && e.target === activeModal) closeModal();
  });

  // Esc + focus trap
  document.addEventListener('keydown', (e) => {
    if (!activeModal) return;
    if (e.key === 'Escape') { e.preventDefault(); closeModal(); }
    else if (e.key === 'Tab') {
      const f = getFocusable(activeModal); if (!f.length) return;
      const first = f[0], last = f[f.length - 1];
      if (e.shiftKey && document.activeElement === first) { e.preventDefault(); last.focus(); }
      else if (!e.shiftKey && document.activeElement === last) { e.preventDefault(); first.focus(); }
    }
  });

  // Tabs
  document.addEventListener('click', (e) => {
    const btn = e.target.closest('[data-tab]'); if (!btn) return;
    const panelId = btn.getAttribute('data-tab');
    const modal = btn.closest('[role="dialog"]');
    modal.querySelectorAll('.tab-btn').forEach(b => b.classList.remove('bg-neutral-100','dark:bg-neutral-900'));
    btn.classList.add('bg-neutral-100','dark:bg-neutral-900');
    modal.querySelectorAll('.tab-panel').forEach(p => p.classList.add('hidden'));
    const panel = modal.querySelector('#' + panelId);
    if (panel) panel.classList.remove('hidden');
  });
})();
</script>

<body class="bg-white text-gray-800 dark:bg-neutral-950 dark:text-neutral-100 font-body selection:bg-brand-300/40">
  <!-- Skip link -->
  <a href="#main" class="sr-only focus:not-sr-only focus:fixed focus:top-4 focus:left-4 bg-brand-500 text-white px-3 py-2 rounded-lg">Skip to content</a>

  <!-- Header / Nav -->
  <header class="sticky top-0 z-50 backdrop-blur bg-white/75 dark:bg-neutral-950/75 border-b border-neutral-200/70 dark:border-neutral-800">
    <div class="max-w-6xl mx-auto px-4">
      <div class="flex items-center justify-between h-16">
        <a href="#home" class="flex items-center gap-3 group">
          <div class="h-9 w-9 rounded-xl bg-gradient-to-br from-brand-500 to-amber-500 shadow-mellow"></div>
          <span class="font-display text-lg font-semibold group-hover:text-brand-600 dark:group-hover:text-brand-400 transition-colors">Mohammed Saferi Rahman</span>
        </a>
        <nav class="hidden md:flex items-center gap-6 text-sm font-medium">
          <a href="#research" class="hover:text-brand-600 dark:hover:text-brand-400">Research</a>
          <a href="#pubs" class="hover:text-brand-600 dark:hover:text-brand-400">Publications</a>
          <a href="#projects" class="hover:text-brand-600 dark:hover:text-brand-400">Projects</a>
          <a href="#teaching" class="hover:text-brand-600 dark:hover:text-brand-400">Teaching</a>
          <a href="#service" class="hover:text-brand-600 dark:hover:text-brand-400">Service</a>
          <a href="#awards" class="hover:text-brand-600 dark:hover:text-brand-400">Awards</a>
          <a href="#contact" class="hover:text-brand-600 dark:hover:text-brand-400">Contact</a>
          <a href="assets/Mohammed_Saferi_CV.pdf" class="inline-flex items-center gap-2 bg-neutral-900 text-white dark:bg-white dark:text-neutral-900 px-3 py-1.5 rounded-xl hover:opacity-90" download>
            <span>CV</span>
          </a>
          <button id="themeToggle" class="rounded-xl border border-neutral-200 dark:border-neutral-800 px-2 py-1" aria-label="Toggle theme">üåì</button>
        </nav>
        <button id="menuBtn" class="md:hidden p-2" aria-label="Open menu">‚ò∞</button>
      </div>
    </div>
    <!-- Mobile menu -->
    <div id="mobileMenu" class="md:hidden hidden border-t border-neutral-200 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4 py-3 grid grid-cols-2 gap-3 text-sm">
        <a href="#research" class="hover:text-brand-600 dark:hover:text-brand-400">Research</a>
        <a href="#pubs" class="hover:text-brand-600 dark:hover:text-brand-400">Publications</a>
        <a href="#projects" class="hover:text-brand-600 dark:hover:text-brand-400">Projects</a>
        <a href="#teaching" class="hover:text-brand-600 dark:hover:text-brand-400">Teaching</a>
        <a href="#service" class="hover:text-brand-600 dark:hover:text-brand-400">Service</a>
        <a href="#awards" class="hover:text-brand-600 dark:hover:text-brand-400">Awards</a>
        <a href="#contact" class="hover:text-brand-600 dark:hover:text-brand-400">Contact</a>
        <a href="assets/Mohammed_Saferi_CV.pdf" download class="hover:text-brand-600 dark:hover:text-brand-400">CV</a>
      </div>
    </div>
  </header>

  <main id="main">
    <!-- Hero -->
    <section id="home" class="relative overflow-hidden">
      <div class="absolute inset-0 bg-[radial-gradient(ellipse_at_top,_var(--tw-gradient-stops))] from-brand-500/10 via-transparent to-transparent pointer-events-none"></div>
      <div class="max-w-6xl mx-auto px-4 py-20 md:py-28">
        <div class="grid md:grid-cols-12 gap-10 items-center">
          <div class="md:col-span-7">
            <p class="uppercase tracking-widest text-xs text-neutral-500 dark:text-neutral-400">Computer Science ¬∑ HCI & Ubiquitous Computing ¬∑ LLM</p>
            <h1 class="mt-3 font-display text-4xl md:text-6xl font-extrabold leading-tight">
              Mohammed Saferi Rahman
            </h1>
            <p class="mt-5 max-w-[65ch] text-[18px] md:text-[20px] leading-relaxed text-neutral-300">
              I am a PhD student in Computer Science at Florida State University with expertise in ubiquitous computing, human-computer interaction, and AI. I build human-centered, context-aware systems that leverage multimodal data and LLMs to perceive, model, and adapt to everyday scenarios. My interests span sensing and inference, representation learning, and interaction design. My goal is to translate ubiquitous signals into useful, trustworthy AI that supports people in real contexts by improving awareness, decision-making, and well-being without intruding on it.
            </p>
            <!-- <p class="mt-4 text-lg md:text-xl text-neutral-600 dark:text-neutral-300 max-w-[70ch]">
              I am a PhD student in Computer Science at Florida State University with expertise in Ubiquitous Computing, Human-Computer Interaction, and AI. My research centers on building human-centered, context-aware systems that leverage multimodal data and LLMs to perceive, model, and adapt to everyday scenarios. My interests span sensing and inference, representation learning, and interaction design. My goal is to translate ubiquitous signals into useful, trustworthy AI that supports people in real contexts, such as, improving awareness, decision-making, and well-being without intruding on it.
            </p> -->
            <div class="mt-8 flex flex-wrap items-center gap-3">
              <a href="#research" class="inline-flex items-center gap-2 bg-brand-600 text-white px-5 py-3 rounded-2xl shadow-mellow hover:bg-brand-700 transition-transform duration-150 hover:-translate-y-0.5">>
                Explore Research
              </a>
              <a href="#contact" class="inline-flex items-center gap-2 px-5 py-3 rounded-2xl border border-neutral-200 dark:border-neutral-800 hover:bg-neutral-50 dark:hover:bg-neutral-900">
                Get in touch
              </a>
            </div>
            <div class="mt-6 flex items-center gap-4 text-sm text-neutral-500 dark:text-neutral-400">
              <a href="https://github.com/saferi1023" class="hover:text-brand-600 dark:hover:text-brand-400">GitHub</a>
              <a href="https://scholar.google.com/citations?user=IbT91PoAAAAJ&hl=en" class="hover:text-brand-600 dark:hover:text-brand-400">Google Scholar</a>
              <a href="https://www.linkedin.com/in/md-saferi-rahman/" class="hover:text-brand-600 dark:hover:text-brand-400">LinkedIn</a>
              <a href="mailto:mr21co@fsu.edu" class="hover:text-brand-600 dark:hover:text-brand-400">Email</a>
            </div>
          </div>
          <div class="md:col-span-5 flex justify-center">
            <img src="assets/profile.jpg" alt="Portrait of Mohammed Saferi" class="w-56 h-56 md:w-72 md:h-72 rounded-3xl object-cover ring-1 ring-neutral-200 dark:ring-neutral-800 shadow-mellow" />
          </div>
        </div>
      </div>
    </section>

    <!-- Research highlights -->
    <section id="research" class="py-16 md:py-24 border-t border-neutral-200/70 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4">
        <div class="flex items-end justify-between flex-wrap gap-4">
          <h2 class="font-display text-2xl md:text-3xl font-bold">Research</h2>
          <a href="#pubs" class="text-sm text-brand-600 dark:text-brand-400 hover:underline">See Publications</a>
        </div>
        <p class="mt-3 text-neutral-600 dark:text-neutral-300 max-w-3xl">My work spans human‚ÄìAI communication, well‚Äëbeing analytics with the JD‚ÄìR model, LLM‚Äëdriven simulation for training, and wearable/ubiquitous sensing.</p>
        <div class="mt-8 grid md:grid-cols-2 gap-6"> 
          <!-- Card 1 -->
          <article class="rounded-2xl border border-neutral-200 dark:border-neutral-800 overflow-hidden">
            <img src="assets/Grad-Wellbeing cover photo AI.png" alt="Grad Wellbeing project cover" class="w-full h-48 object-cover" />
            <div class="p-5">
              <h3 class="font-semibold text-lg">AI‚ÄëDriven Monitoring of PhD Student Well‚Äëbeing</h3>
              <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">Hierarchical information extraction and response simulation to infer JD‚ÄìR factors from chats, emails, calendars, and sensors.</p>
              <div class="mt-3 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">UbiComp</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
              <button
                class="mt-3 inline-flex text-brand-600 dark:text-brand-400 text-sm hover:underline"
                data-modal-open="modal-jdr">
                Learn more ‚Üí
              </button>
            </div>
          </article>

          
          <!-- <article class="group rounded-2xl border border-neutral-200 dark:border-neutral-800 p-5 hover:shadow-mellow transition-shadow bg-white dark:bg-neutral-950 transition-transform duration-150 hover:-translate-y-1 hover:shadow-mellow">
            <div class="h-40 rounded-xl bg-gradient-to-br from-brand-500/20 to-amber-500/20 flex items-center justify-center text-sm text-neutral-600 dark:text-neutral-300">JD‚ÄìR LLM Pipeline</div>
            <h3 class="mt-4 font-semibold text-lg">AI‚ÄëDriven Monitoring of PhD Student Well‚Äëbeing</h3>
            <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">Hierarchical information extraction and response simulation to infer JD‚ÄìR factors from chats, emails, calendars, and sensors.</p>
            <button
              class="mt-3 inline-flex text-brand-600 dark:text-brand-400 text-sm hover:underline"
              data-modal-open="modal-jdr">
              Learn more ‚Üí
            </button>
          </article> -->
          
          <!-- Card 2 -->
          <article class="rounded-2xl border border-neutral-200 dark:border-neutral-800 overflow-hidden">
            <img src="assets/VP-poster.png" alt="Grad Wellbeing project cover" class="w-full h-48 object-cover" />
            <div class="p-5">
              <h3 class="font-semibold text-lg">Emotion‚Äëaware LLM Virtual Patient for Training</h3>
              <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">A conversational avatar in Unity for telehealth education with facial‚Äëexpression cues and scenario authoring.</p>
              <div class="mt-3 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">UbiComp</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
              <button
                class="mt-3 inline-flex text-brand-600 dark:text-brand-400 text-sm hover:underline"
                data-modal-open="modal-vp">
                Learn more ‚Üí
              </button>
            </div>
          </article>

          
          <!-- <article class="group rounded-2xl border border-neutral-200 dark:border-neutral-800 p-5 hover:shadow-mellow transition-shadow bg-white dark:bg-neutral-950 transition-transform duration-150 hover:-translate-y-1 hover:shadow-mellow">
            <div class="h-40 rounded-xl bg-gradient-to-br from-teal-500/20 to-cyan-500/20 flex items-center justify-center text-sm text-neutral-600 dark:text-neutral-300">Virtual Patient</div>
            <h3 class="mt-4 font-semibold text-lg">Emotion‚Äëaware LLM Virtual Patient for Training</h3>
            <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">A conversational avatar in Unity for telehealth education with facial‚Äëexpression cues and scenario authoring.</p>
            <button
              class="mt-3 inline-flex text-brand-600 dark:text-brand-400 text-sm hover:underline"
              data-modal-open="modal-vp">
              Learn more ‚Üí
            </button>
          </article> -->
          
          <!-- Card 3 -->
          <article class="rounded-2xl border border-neutral-200 dark:border-neutral-800 overflow-hidden">
            <img src="assets/capacitive-sensing-cover.png" alt="Grad Wellbeing project cover" class="w-full h-48 object-cover" />
            <div class="p-5">
              <h3 class="font-semibold text-lg">Capacitive‚ÄëSensing Garments (CSG) for recognizing Dyadic Social Interaction</h3>
              <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">Capacitive-sensing shirt that turns everyday clothing into a privacy-preserving sensor, classifying dyadic social interactions from proximity and touch signals in real time.</p>
              <div class="mt-3 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">UbiComp</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
              <button
                class="mt-3 inline-flex text-brand-600 dark:text-brand-400 text-sm hover:underline"
                data-modal-open="modal-csg">
                Learn more ‚Üí
              </button>
            </div>
          </article>
          
          <!-- <article class="group rounded-2xl border border-neutral-200 dark:border-neutral-800 p-5 hover:shadow-mellow transition-shadow bg-white dark:bg-neutral-950 transition-transform duration-150 hover:-translate-y-1 hover:shadow-mellow">
            <div class="h-40 rounded-xl bg-gradient-to-br from-purple-500/20 to-fuchsia-500/20 flex items-center justify-center text-sm text-neutral-600 dark:text-neutral-300">UbiComp Wearables</div>
            <h3 class="mt-4 font-semibold text-lg">Capacitive‚ÄëSensing Garments for Social Interaction</h3>
            <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">Custom electrode arrays and embedded sensing to classify dyadic interaction patterns beyond the wearer.</p>
            <button
              class="mt-3 inline-flex text-brand-600 dark:text-brand-400 text-sm hover:underline"
              data-modal-open="modal-wearables">
              Learn more ‚Üí
            </button>
          </article> -->

          <!-- Card 4 -->
          <article class="rounded-2xl border border-neutral-200 dark:border-neutral-800 overflow-hidden">
            <img src="assets/Text2IMU-poster.png" alt="Text2IMU project cover" class="w-full h-48 object-cover" />
            <div class="p-5">
              <h3 class="font-semibold text-lg">Generating Realistic Inertial Sensor Data from Natural-Language Activity Descriptions</h3>
              <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">Converting natural-language activity prompts into realistic synthetic IMU signals for rapid, low-cost human activity recognition research.</p>
              <div class="mt-3 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">UbiComp</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
              <button
                class="mt-3 inline-flex text-brand-600 dark:text-brand-400 text-sm hover:underline"
                data-modal-open="modal-text2imu">
                Learn more ‚Üí
              </button>
            </div>
          </article>
          
        </div>
      </div>
    </section>

    <!-- Publications -->
    <section id="pubs" class="py-16 md:py-24 border-t border-neutral-200/70 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="font-display text-2xl md:text-3xl font-bold">Publications</h2>
        <p class="mt-3 text-neutral-600 dark:text-neutral-300">Selected peer‚Äëreviewed papers and preprints.</p>
        <ol class="mt-6 space-y-6">
          <!-- Example item -->
          <li class="p-5 rounded-2xl border border-neutral-200 dark:border-neutral-800">
            <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-3">
              <div>
                <h3 class="font-semibold">JDR-LLM: Inferring Job Demands and Resources of PhD Students Using Multimodal LLM-Based Framework</h3>
                <p class="text-sm text-neutral-600 dark:text-neutral-400">Mohammed Saferi Rahman, Te-Yen Wu (2025). Preprint (Submitted to CHI'26).</p>
                <div class="mt-2 flex flex-wrap gap-3 text-sm">
                  <a class="underline hover:no-underline" href="#">PDF</a>
                  <a class="underline hover:no-underline" href="https://github.com/saferi1023/GradWellbeing-App">Code</a>
                </div>
              </div>
              <div class="text-sm shrink-0 text-neutral-500 dark:text-neutral-400">HCI ¬∑ UbiComp ¬∑ LLM</div>
            </div>
          </li>
          <!-- Example item -->
          <li class="p-5 rounded-2xl border border-neutral-200 dark:border-neutral-800">
            <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-3">
              <div>
                <h3 class="font-semibold">Escape Rooms in Nursing Education: How GPA, Collaborative Problem Solving, and Gameful Experience are related</h3>
                <p class="text-sm text-neutral-600 dark:text-neutral-400">Chaewon Kim, James Gray, Veronica Brewer, Mohammed Saferi Rahman, Shantona Panday. Proceedings of the 18th International Conference of the Learning Sciences - ICLS (2024).</p>
                <div class="mt-2 flex flex-wrap gap-3 text-sm">
                  <a class="underline hover:no-underline" href="assets/ICLS2024_1167-1170 (1).pdf">PDF</a>
                  <a class="underline hover:no-underline" href="	https://doi.org/10.22318/icls2024.683835">DOI</a>
                </div>
              </div>
              <div class="text-sm shrink-0 text-neutral-500 dark:text-neutral-400">CSCW/CSCL ¬∑ Collaborative Problem Solving</div>
            </div>
          </li>
          <!-- Example item -->
          <li class="p-5 rounded-2xl border border-neutral-200 dark:border-neutral-800">
            <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-3">
              <div>
                <h3 class="font-semibold">Double deep Q-learning and faster R-Cnn-based autonomous vehicle navigation and obstacle avoidance in dynamic environment</h3>
                <p class="text-sm text-neutral-600 dark:text-neutral-400">Razin Bin Issa, Mohammed Saferi Rahman, Modhumonty Das, Monika Barua, Md Khalilur Rhaman, Kazi Shah Nawaz Ripon, Md Golam Rabiul Alam. Sensors Journal (2021), 21, 1468.</p>
                <div class="mt-2 flex flex-wrap gap-3 text-sm">
                  <a class="underline hover:no-underline" href="assets/sensors-21-01468-v3.pdf">PDF</a>
                  <a class="underline hover:no-underline" href="https://doi.org/10.3390/s21041468">DOI</a>
                </div>
              </div>
              <div class="text-sm shrink-0 text-neutral-500 dark:text-neutral-400">AV Navigation ¬∑ DDQN ¬∑ Faster R-CNN</div>
            </div>
          </li>
          <!-- Example item -->
          <li class="p-5 rounded-2xl border border-neutral-200 dark:border-neutral-800">
            <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-3">
              <div>
                <h3 class="font-semibold">Reinforcement learning based autonomous vehicle for exploration and exploitation of undiscovered track</h3>
                <p class="text-sm text-neutral-600 dark:text-neutral-400">Razin Bin Issa, Mohammed Saferi Rahman, Modhumonty Das, Monika Barua, Md Golam Rabiul Alam. International Conference on Information Networking (ICOIN), Barcelona, Spain, (2020)</p>
                <div class="mt-2 flex flex-wrap gap-3 text-sm">
                  <a class="underline hover:no-underline" href="assets/Reinforcement_Learning_based_Autonomous_Vehicle_for_Exploration_and_Exploitation_of_Undiscovered_Track (1).pdf">PDF</a>
                  <a class="underline hover:no-underline" href="https://doi.org/10.1109/icoin48656.2020.9016539">DOI</a>
                </div>
              </div>
              <div class="text-sm shrink-0 text-neutral-500 dark:text-neutral-400">AV Navigation ¬∑ DDQN ¬∑ Faster R-CNN</div>
            </div>
          </li>
          <!-- Duplicate li elements for real papers -->
        </ol>
      </div>
    </section>

    <!-- Projects -->
    <section id="projects" class="py-16 md:py-24 border-t border-neutral-200/70 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="font-display text-2xl md:text-3xl font-bold">Projects</h2>
        <div class="mt-8 grid md:grid-cols-3 gap-6">
          
          <article class="rounded-2xl border border-neutral-200 dark:border-neutral-800 overflow-hidden">
            <img src="assets/Grad-Wellbeing cover photo AI.png" alt="Grad Wellbeing project cover" class="w-full h-48 object-cover" />
            <div class="p-5">
              <h3 class="font-semibold text-lg">Grad Wellbeing ‚Äî A Multi-Modal LLM based approach</h3>
              <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">React Native app + Python pipeline analyzing academic communications to infer JD‚ÄìR factors for proactive support.</p>
              <div class="mt-3 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">Python</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">React Native</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
              <div class="mt-4 flex gap-4 text-sm">
                <a href="#" class="underline">Repo</a>
                <a href="#" class="underline">Demo</a>
              </div>
            </div>
          </article>
          
          <article class="rounded-2xl border border-neutral-200 dark:border-neutral-800 overflow-hidden">
            <img src="assets/VP-poster.png" alt="Virtual patient project cover" class="w-full h-48 object-cover" />
            <div class="p-5">
              <h3 class="font-semibold text-lg">Virtual Patient ‚Äî Emotion‚ÄëAware Telehealth Avatar</h3>
              <p class="mt-2 text-sm text-neutral-600 dark:text-neutral-400">Unity‚Äëbased avatar integrating TTS/ASR and LLM reasoning for clinical‚Äëskills practice.</p>
              <div class="mt-3 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">Unity</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">OpenAI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">Emotion</span>
              </div>
              <div class="mt-4 flex gap-4 text-sm">
                <a href="#" class="underline">Repo</a>
                <a href="#" class="underline">Demo</a>
              </div>
            </div>
          </article>
          
        </div>
      </div>
    </section>

    <!-- Teaching -->
    <section id="teaching" class="py-16 md:py-24 border-t border-neutral-200/70 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="font-display text-2xl md:text-3xl font-bold">Teaching</h2>
        <ul class="mt-6 space-y-3">
          <li class="p-4 rounded-xl border border-neutral-200 dark:border-neutral-800 flex items-center justify-between">
            <div>
              <p class="font-medium">HCI (Undergraduate) ‚Äî Teaching Assistant</p>
              <p class="text-sm text-neutral-600 dark:text-neutral-400">Fall 2024 ¬∑ Led labs, designed assignments on prototyping & evaluation.</p>
            </div>
            <span class="text-xs px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">FSU</span>
          </li>
          <!-- Add more items -->
        </ul>
      </div>
    </section>

    <!-- Service & Awards -->
    <section id="service" class="py-16 md:py-24 border-t border-neutral-200/70 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="font-display text-2xl md:text-3xl font-bold">Service</h2>
        <p class="mt-3 text-neutral-600 dark:text-neutral-300">Reviewer: CHI, IMWUT (2025‚Äì).</p>
      </div>
    </section>

    <section id="awards" class="py-16 md:py-24 border-t border-neutral-200/70 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="font-display text-2xl md:text-3xl font-bold">Awards</h2>
        <ul class="mt-6 list-disc pl-6 space-y-2 text-neutral-700 dark:text-neutral-300">
          <li>Graduate Research Assistantship, FSU</li>
          <li>PIE Teaching Certification</li>
        </ul>
      </div>
    </section>

    <!-- Contact -->
    <section id="contact" class="py-16 md:py-24 border-t border-neutral-200/70 dark:border-neutral-800">
      <div class="max-w-6xl mx-auto px-4">
        <div class="grid md:grid-cols-2 gap-10 items-start">
          <div>
            <h2 class="font-display text-2xl md:text-3xl font-bold">Contact</h2>
            <p class="mt-3 text-neutral-600 dark:text-neutral-300">I‚Äôm actively seeking Summer 2026 research internships in HCI, UbiComp, and human‚ÄëAI systems. If you‚Äôre hiring, I‚Äôd love to chat.</p>
            <div class="mt-6 space-y-2 text-neutral-700 dark:text-neutral-300">
              <p><strong>Email:</strong> firstname.lastname@university.edu</p>
              <p><strong>Office:</strong> Department of Computer Science, Florida State University</p>
            </div>
            <div class="mt-6 flex gap-4">
              <a href="mailto:firstname.lastname@university.edu" class="inline-flex items-center gap-2 bg-brand-600 text-white px-5 py-3 rounded-2xl shadow-mellow hover:bg-brand-700">Email me</a>
              <a href="assets/Mohammed_Saferi_CV.pdf" class="inline-flex items-center gap-2 px-5 py-3 rounded-2xl border border-neutral-200 dark:border-neutral-800 hover:bg-neutral-50 dark:hover:bg-neutral-900" download>Download CV</a>
            </div>
          </div>
          <form class="rounded-2xl border border-neutral-200 dark:border-neutral-800 p-6 bg-white dark:bg-neutral-950" onsubmit="event.preventDefault(); alert('Thanks! Your message is not wired to a backend yet. Replace form action with Formspree or Netlify.');">
            <h3 class="font-semibold text-lg">Quick message</h3>
            <div class="mt-4 grid gap-4">
              <label class="block text-sm">Name
                <input type="text" required class="mt-1 w-full rounded-xl border border-neutral-300 dark:border-neutral-700 bg-transparent px-3 py-2 focus:outline-none focus:ring-2 focus:ring-brand-500" />
              </label>
              <label class="block text-sm">Email
                <input type="email" required class="mt-1 w-full rounded-xl border border-neutral-300 dark:border-neutral-700 bg-transparent px-3 py-2 focus:outline-none focus:ring-2 focus:ring-brand-500" />
              </label>
              <label class="block text-sm">Message
                <textarea rows="4" required class="mt-1 w-full rounded-xl border border-neutral-300 dark:border-neutral-700 bg-transparent px-3 py-2 focus:outline-none focus:ring-2 focus:ring-brand-500"></textarea>
              </label>
              <button class="inline-flex items-center justify-center gap-2 bg-neutral-900 text-white dark:bg-white dark:text-neutral-900 px-4 py-2 rounded-xl hover:opacity-90">Send</button>
              <p class="text-xs text-neutral-500 dark:text-neutral-400">Use <a href="https://formspree.io" class="underline">Formspree</a> or <a href="https://www.netlify.com/products/forms/" class="underline">Netlify Forms</a> for no‚Äëbackend submissions on GitHub Pages.</p>
            </div>
          </form>
        </div>
      </div>
    </section>
    <!-- Modal: JD‚ÄìR -->


    <!-- Modal: JD‚ÄìR (detail overlay) -->
    <div id="modal-jdr"
         class="fixed inset-0 z-[60] hidden items-start md:items-center justify-center p-0 md:p-6 overscroll-contain"
         role="dialog" aria-modal="true" aria-labelledby="modal-jdr-title">
      <!-- Backdrop -->
      <div class="absolute inset-0 bg-black/60 backdrop-blur-sm" data-modal-close></div>
    
      <!-- Panel -->
      <div class="relative w-full md:max-w-5xl max-h-[90vh] grid grid-rows-[auto,1fr] overflow-hidden rounded-2xl 
                  bg-white dark:bg-neutral-950 border border-neutral-200 dark:border-neutral-800 shadow-mellow">
    
        <!-- Header -->
        <div class="sticky top-0 z-10 bg-white dark:bg-neutral-950 border-b border-neutral-200 dark:border-neutral-800">
          <div class="flex items-start justify-between gap-4 p-4">
            <div>
              <h3 id="modal-jdr-title" class="text-lg md:text-xl font-semibold">
                AI-Driven Monitoring of PhD Student Well-being
              </h3>
              <div class="mt-1 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">UbiComp</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
            </div>
            <button class="rounded-lg p-2 hover:bg-neutral-100 dark:hover:bg-neutral-900" data-modal-close aria-label="Close">‚úï</button>
          </div>
          <!-- Banner -->
          <div class="w-full bg-neutral-950 border-t border-neutral-200 dark:border-neutral-800 flex items-center justify-center">
            <img
              src="assets/gradwelbeing-poster.png" alt="Project banner"
              alt="Project poster"
              class="w-full h-auto max-h-[40vh] md:max-h-[50vh] object-contain"
              loading="lazy" decoding="async"
            >
          </div>
          <!-- <img src="assets/gradwelbeing-poster.png" alt="Project banner"
               class="w-full h-full md:h-48 object-cover border-t border-neutral-200 dark:border-neutral-800"> -->
          <!-- Tabs -->
          <nav class="flex gap-2 overflow-x-auto p-3 border-t border-neutral-200 dark:border-neutral-800 text-sm">
            <button class="tab-btn px-3 py-1.5 rounded-xl bg-neutral-100 dark:bg-neutral-900"
                    data-tab="jdr-overview">Overview</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900"
                    data-tab="jdr-methods">Methods</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900"
                    data-tab="jdr-data">Data</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900"
                    data-tab="jdr-results">Results</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900"
                    data-tab="jdr-ethics">Ethics & Privacy</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900"
                    data-tab="jdr-artifacts">Artifacts</button>
          </nav>
        </div>
    
        <!-- Body (scrollable) -->
        <section class="p-5 overflow-y-auto max-h-[calc(90vh-12rem)] space-y-8">
    
          <!-- OVERVIEW -->
          <div id="jdr-overview" class="tab-panel">
            <p class="text-neutral-700 dark:text-neutral-300 leading-relaxed">
              PhD students frequently face high job demands and limited resources, increasing their risk of mental health challenges. While the Job Demands‚ÄìResources (JD-R) model provides a useful framework for assessing well-being, it traditionally relies on self-reports. In this work, we propose a multimodal approach that uses large language models (LLMs) to infer JD-R factors from mobile sensor data (GPS, steps, sleep) and digital interaction data (calendars, emails, and chat logs).
              We conducted a four-week study with 14 PhD students and introduced a two-stage prompting framework: first extracting relevant context, then simulating Likert-scale responses to JD-R questions. We explore two calibration methods, <strong>personal offset calibration (POC)</strong> and <strong>personal contextual calibration (PCC)</strong> to improve personalization. Our approach significantly outperforms direct prompting, achieving MAEs of <strong>0.3815</strong> and <strong>0.3441</strong> for job demand and resource scores, respectively. Ablation studies further highlight the value of combining sensing and textual data for passive, continuous well-being assessment.
            </p>
            <!-- <ul class="mt-4 grid md:grid-cols-2 gap-3 text-sm text-neutral-600 dark:text-neutral-400">
              <li>‚Ä¢ Focus: HCI ¬∑ UbiComp ¬∑ Human-centered AI</li>
              <li>‚Ä¢ Modalities: activity/location, device signals, messages/email, calendars</li>
              <li>‚Ä¢ Modeling: multimodal representation + LLM reasoning</li>
              <li>‚Ä¢ Outcomes: perceived stress, peer support, supervision, infrastructure, intellectual climate</li>
            </ul> -->
          </div>
    
          <!-- METHODS -->
          <div id="jdr-methods" class="tab-panel hidden">
            <ol class="list-decimal pl-5 space-y-2 text-neutral-700 dark:text-neutral-300 text-sm">
              <li><strong>Ingestion:</strong> weekly exports from chats/email/calendars; mobile/wearable logs.</li>
              <li><strong>Preprocessing:</strong> normalization, time-windowing, privacy filters, content redaction.</li>
              <li><strong>Information Extraction (IE):</strong> LLM prompts summarize salient events and contexts per JD‚ÄìR topic.</li>
              <li><strong>Response Simulation (RS):</strong> LLM simulates Likert-scale answers for JD‚ÄìR sub-questions.</li>
              <li><strong>Scoring:</strong> aggregate to factor-level scores (stress; peer support; supervision; infrastructure; intellectual climate).</li>
              <li><strong>Evaluation:</strong> MAE and Spearman correlation against ground truth questionnaires; ablations across modalities.</li>
            </ol>
            <p class="mt-3 text-xs text-neutral-500 dark:text-neutral-400">
              Note: The current pipeline simulates scores directly from weekly sub-question responses; calibration is optional.
            </p>
          </div>
    
          <!-- DATA -->
          <div id="jdr-data" class="tab-panel hidden">
            <div class="grid md:grid-cols-2 gap-4 text-sm text-neutral-700 dark:text-neutral-300">
              <div>
                <h4 class="font-medium mb-1">Digital Interaction</h4>
                <ul class="list-disc pl-5 space-y-1">
                  <li>Chats (role, tone, frequency patterns)</li>
                  <li>Email (threads, response cadence)</li>
                  <li>Calendars (workload, meeting context)</li>
                </ul>
              </div>
              <div>
                <h4 class="font-medium mb-1">Mobile/Wearable</h4>
                <ul class="list-disc pl-5 space-y-1">
                  <li>Activity & steps, sleep/wake windows</li>
                  <li>Location regularity & transitions</li>
                  <li>On-device sensing summaries</li>
                </ul>
              </div>
            </div>
          </div>
    
          <!-- RESULTS -->
          <div id="jdr-results" class="tab-panel hidden">
            <div class="grid sm:grid-cols-3 gap-4">
              <div class="rounded-xl border border-neutral-200 dark:border-neutral-800 p-4">
                <p class="text-xs text-neutral-500 dark:text-neutral-400">Metric</p>
                <p class="text-lg font-semibold">MAE</p>
                <p class="text-sm text-neutral-600 dark:text-neutral-400">Placeholder (add values)</p>
              </div>
              <div class="rounded-xl border border-neutral-200 dark:border-neutral-800 p-4">
                <p class="text-xs text-neutral-500 dark:text-neutral-400">Correlation</p>
                <p class="text-lg font-semibold">Spearman‚Äôs œÅ</p>
                <p class="text-sm text-neutral-600 dark:text-neutral-400">Placeholder (add values)</p>
              </div>
              <div class="rounded-xl border border-neutral-200 dark:border-neutral-800 p-4">
                <p class="text-xs text-neutral-500 dark:text-neutral-400">Ablations</p>
                <p class="text-lg font-semibold">Modalities</p>
                <p class="text-sm text-neutral-600 dark:text-neutral-400">Chat-only vs +Calendar vs +Sensors</p>
              </div>
            </div>
          </div>
    
          <!-- ETHICS -->
          <div id="jdr-ethics" class="tab-panel hidden">
            <ul class="list-disc pl-5 space-y-2 text-sm text-neutral-700 dark:text-neutral-300">
              <li><strong>Consent & Governance:</strong> explicit opt-in, revocation anytime, IRB alignment.</li>
              <li><strong>Data Minimization:</strong> collect only signals needed for the stated purpose.</li>
              <li><strong>Privacy:</strong> local redaction, secure storage, least-privilege access.</li>
              <li><strong>Transparency:</strong> user-facing summaries and explanations for model outputs.</li>
            </ul>
          </div>
    
          <!-- ARTIFACTS -->
          <div id="jdr-artifacts" class="tab-panel hidden">
            <div class="flex flex-wrap gap-3">
              <a href="assets/CHI26-JDR_LLM__Inferring_Job_Demands_and_Resources_of_PhD_Students_Using_Multimodal_LLM_Based_Framework.pdf"
                 class="inline-flex items-center gap-2 bg-neutral-900 text-white dark:bg-white dark:text-neutral-900 px-4 py-2 rounded-xl hover:opacity-90">
                PDF
              </a>
              <a href="https://github.com/saferi1023/GradWellbeing-App"
                 class="inline-flex items-center gap-2 border border-neutral-300 dark:border-neutral-700 px-4 py-2 rounded-xl hover:bg-neutral-50 dark:hover:bg-neutral-900">
                Code (App)
              </a>
              <a href="#"
                 class="inline-flex items-center gap-2 border border-neutral-300 dark:border-neutral-700 px-4 py-2 rounded-xl hover:bg-neutral-50 dark:hover:bg-neutral-900">
                Slides / Poster
              </a>
              <a href="#"
                 class="inline-flex items-center gap-2 border border-neutral-300 dark:border-neutral-700 px-4 py-2 rounded-xl hover:bg-neutral-50 dark:hover:bg-neutral-900">
                BibTeX
              </a>
            </div>
          </div>
    
          <!-- Footer actions -->
          <div class="pt-2 border-t border-neutral-200 dark:border-neutral-800 flex items-center justify-end">
            <button class="mt-3 inline-flex items-center gap-2 bg-brand-600 text-white px-4 py-2 rounded-xl hover:bg-brand-700"
                    data-modal-close data-autofocus>Close</button>
          </div>
        </section>
      </div>
    </div>

    
    <!-- Modal: Virtual Patient System -->
    <div id="modal-vp"
         class="fixed inset-0 z-[60] hidden items-start md:items-center justify-center p-0 md:p-6 overscroll-contain"
         role="dialog" aria-modal="true" aria-labelledby="modal-vp-title">
      <!-- Backdrop -->
      <div class="absolute inset-0 bg-black/60 backdrop-blur-sm" data-modal-close></div>
    
      <!-- Panel -->
      <div class="relative w-full md:max-w-5xl max-h-[90vh] grid grid-rows-[auto,1fr] overflow-hidden rounded-2xl 
                  bg-white dark:bg-neutral-950 border border-neutral-200 dark:border-neutral-800 shadow-mellow">
    
        <!-- Header -->
        <div class="sticky top-0 z-10 bg-white dark:bg-neutral-950 border-b border-neutral-200 dark:border-neutral-800">
          <div class="flex items-start justify-between gap-4 p-4">
            <div>
              <h3 id="modal-vp-title" class="text-lg md:text-xl font-semibold">
                Emotion-Aware Virtual Patient System
              </h3>
              <div class="mt-1 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">UbiComp</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
            </div>
            <button class="rounded-lg p-2 hover:bg-neutral-100 dark:hover:bg-neutral-900" data-modal-close aria-label="Close">‚úï</button>
          </div>
    
          <!-- Poster banner (no cropping). Export your PDF to PNG/JPG and place in /assets/ -->
          <!-- <div class="w-full bg-neutral-950 border-t border-neutral-200 dark:border-neutral-800">
            <img
              src="assets/VP-poster.png"
              alt="Virtual Patient System poster"
              width="700" height="350"                
              class="block mx-auto w-full h-auto max-h-[60vh] md:max-h-[70vh] object-contain object-center"
              loading="lazy" decoding="async">
          </div> -->

          <div class="w-full flex justify-center">
            <div class="w-full max-w-[400px] md:max-w-[400px]">
              <img
                src="assets/VP-poster.png"
                alt="Virtual Patient System poster"
                width="1000" height="500"
                class="block w-full h-auto rounded-xl ring-1 ring-neutral-800/50 object-contain"
                loading="lazy" decoding="async">
            </div>
          </div>
    
          <!-- Tabs -->
          <nav class="flex gap-2 overflow-x-auto p-3 border-t border-neutral-200 dark:border-neutral-800 text-sm">
            <button class="tab-btn px-3 py-1.5 rounded-xl bg-neutral-100 dark:bg-neutral-900" data-tab="vp-overview">Overview</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900" data-tab="vp-system">System</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900" data-tab="vp-signals">Signals & Metrics</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900" data-tab="vp-methods">Methods</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900" data-tab="vp-study">Study & Future Work</button>
           
          </nav>
        </div>
    
        <!-- Body (scrollable) -->
        <section class="p-5 overflow-y-auto max-h-[calc(90vh-14rem)] space-y-8">
    
          <!-- OVERVIEW -->
          <div id="vp-overview" class="tab-panel">
            <p class="text-neutral-700 dark:text-neutral-300 leading-relaxed">
              We present an emotion-aware, LLM-orchestrated Virtual Patient (VP) system for high-fidelity clinical communication training. A multimodal perception stack fuses streaming transformer ASR transcripts, prosodic features (F0, energy, speaking rate) mapped to Valence/Arousal/Dominance, and vision signals (MediaPipe/OpenCV landmarks and DeepFace expressions). Signals are temporally aligned and aggregated into a latent interaction state. A persona-conditioned dialogue policy built on a tool-augmented LLM generates patient utterances and real-time coaching while enforcing controllable style and safety constraints. The Unity client renders a lifelike avatar with neural TTS and viseme-synchronized animations, supporting configurable symptoms and affect dynamics. We compute SOFTEN (smile, open posture, forward lean, tone, eye contact, nod) and other nonverbal metrics, exposing interpretable dashboards and reproducible logs. Privacy is addressed via on-device redaction, data minimization, and role-segmented storage. Planned evaluations compare VP-augmented training to actor-only baselines and include ablations over modalities and prompting strategies.
              This work contributes a modular multimodal framework for human AI training dialogues and reproducible metrics for communication, empathy, and clinical reasoning. The system supports configurable patient personas and scenarios and provides dashboards that summarize performance over time longitudinally.
            </p>
          </div>
    
          <!-- SYSTEM -->
          <div id="vp-system" class="tab-panel hidden">
            <div class="grid md:grid-cols-2 gap-4 text-sm text-neutral-700 dark:text-neutral-300">
              <div>
                <h4 class="font-medium mb-1">Server</h4>
                <ul class="list-disc pl-5 space-y-1">
                  <li>Evaluates empathy using the SOFTEN metric (Smile, Open posture, Forward lean, Tone, Eye contact, Nod).</li>
                  <li>Tone via VAD (valence, arousal, dominance) model; facial expression with DeepFace.</li>
                  <li>Computer vision features via MediaPipe & OpenCV.</li>
                  <li>Whisper for speech-to-text and expressive text-to-speech.</li>
                  <li>LLM prompts drive dynamic responses and coaching.</li>
                </ul>
              </div>
              <div>
                <h4 class="font-medium mb-1">Client (Unity)</h4>
                <ul class="list-disc pl-5 space-y-1">
                  <li>Realistic avatar (Microsoft Rocketbox) with speech/idle and symptom animations.</li>
                  <li>Emotional states from agitated to relaxed; subtle blinks and micro-motions.</li>
                  <li>Post-encounter summary of SOFTEN metrics + most-frequent facial expression.</li>
                  <li>Optional: hide automated summary and store for human evaluator review.</li>
                </ul>
              </div>
            </div>
          </div>
    
          <!-- SIGNALS & METRICS -->
          <div id="vp-signals" class="tab-panel hidden">
            <ul class="list-disc pl-5 space-y-2 text-sm text-neutral-700 dark:text-neutral-300">
              <li><strong>Non-verbal:</strong> SOFTEN (smile, posture, lean, tone, eye contact, nod)</li>
              <li><strong>Speech & Tone:</strong> Whisper (ASR/TTS), VAD-based affect</li>
              <li><strong>Vision:</strong> MediaPipe & OpenCV features; DeepFace expressions</li>
            </ul>
          </div>
    
          <!-- METHODS -->
          <div id="vp-methods" class="tab-panel hidden">
            <ol class="list-decimal pl-5 space-y-2 text-sm text-neutral-700 dark:text-neutral-300">
              <li>Capture audio/video and interaction events from the Unity client.</li>
              <li>Infer affect & non-verbal cues (VAD, facial expression, SOFTEN components).</li>
              <li>Run LLM policy for dialogue and real-time coaching prompts.</li>
              <li>Synthesize voice for the avatar (TTS) and drive animation states.</li>
              <li>Summarize the encounter and surface feedback dashboards.</li>
            </ol>
          </div>
    
          <!-- STUDY & FUTURE WORK -->
          <div id="vp-study" class="tab-panel hidden">
            <ul class="list-disc pl-5 space-y-2 text-sm text-neutral-700 dark:text-neutral-300">
              <li>Planned study with College of Medicine: additional virtual-patient training vs actor-only training.</li>
              <li>Initial deployments run locally; later, central server for remote access.</li>
              <li>Expand patient diversity and symptom-animation library.</li>
            </ul>
          </div>
    
          <!-- Footer actions -->
          <div class="pt-2 border-t border-neutral-200 dark:border-neutral-800 flex items-center justify-end">
            <button class="mt-3 inline-flex items-center gap-2 bg-brand-600 text-white px-4 py-2 rounded-xl hover:bg-brand-700"
                    data-modal-close data-autofocus>Close</button>
          </div>
        </section>
      </div>
    </div>



    
    <!-- Modal: Wearables -->
    <!-- Modal: Capacitive-Sensing Garment -->
    <div id="modal-csg"
         class="fixed inset-0 z-[60] hidden items-start md:items-center justify-center p-0 md:p-6 overscroll-contain"
         role="dialog" aria-modal="true" aria-labelledby="modal-csg-title">
      <!-- Backdrop -->
      <div class="absolute inset-0 bg-black/60 backdrop-blur-sm" data-modal-close></div>
    
      <!-- Panel -->
      <div class="relative w-full md:max-w-4xl max-h-[90vh] grid grid-rows-[auto,1fr] overflow-hidden
                  rounded-2xl bg-white dark:bg-neutral-950 border border-neutral-200 dark:border-neutral-800 shadow-mellow">
    
        <!-- Header -->
        <div class="sticky top-0 z-10 bg-white dark:bg-neutral-950 border-b border-neutral-200 dark:border-neutral-800">
          <div class="flex items-start justify-between gap-4 p-4">
            <div>
              <h3 id="modal-vp-title" class="text-lg md:text-xl font-semibold">
                Capacitive Sensing Garment (CSG) for Dyadic Social Interaction recognition
              </h3>
              <div class="mt-1 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">UbiComp</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
            </div>
            <button class="rounded-lg p-2 hover:bg-neutral-100 dark:hover:bg-neutral-900" data-modal-close aria-label="Close">‚úï</button>
          </div>

          <div class="w-full flex justify-center">
            <div class="w-full max-w-[400px] md:max-w-[400px]">
              <img
                src="assets/capacitive-sensing-cover.png"
                alt="Capacitive Sensing poster"
                width="1000" height="500"
                class="block w-full h-auto rounded-xl ring-1 ring-neutral-800/50 object-contain"
                loading="lazy" decoding="async">
            </div>
          </div>
    
          <!-- Tabs -->
          <nav class="flex gap-2 overflow-x-auto p-3 border-t border-neutral-200 dark:border-neutral-800 text-sm">
            <button class="tab-btn px-3 py-1.5 rounded-xl bg-neutral-100 dark:bg-neutral-900" data-tab="csg-overview">Overview</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900" data-tab="csg-hardware">Hardware</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900" data-tab="csg-study">Study Design</button>
          </nav>
        </div>


    
        <!-- Body (scrollable) -->
        <section class="p-5 overflow-y-auto max-h-[calc(90vh-14rem)] space-y-8">
    
          <!-- OVERVIEW -->
          <div id="csg-overview" class="tab-panel">
            <p class="text-neutral-700 dark:text-neutral-300 leading-relaxed">
              We investigate a capacitive-sensing garment (CSG) for recognizing dyadic social interactions from clothing-integrated electrodes. The prototype shirt embeds twelve textile capacitive sensing electrodes across torso and arms and streams mutual-capacitance signals while two people perform scripted and semi-naturalistic tasks. In a within-subjects dyad study (N=24; 12 dyads), participants complete 15 tasks spanning five categories‚ÄîExchange, Cooperation, Competition, Conflict, and Accommodation, with baseline calibration and synchronized overhead video for labeling. We extract proximity and contact features (e.g., duration, area-change proxies, proximity gradients, temporal dynamics) and train temporal classifiers to detect presence/approach and classify interaction episodes. Performance is evaluated with within-participant and leave-one-dyad-out protocols and summarized via standard metrics and confusion matrices. Ablations compare all electrodes vs. torso-only vs. arms-only to quantify regional contributions. The study provides the first systematic evidence that garment-integrated capacitive sensing can differentiate multiple social interaction categories, and offers design guidance for electrode placement and sensing ranges for socially aware wearables.
            </p>
          </div>
    
          <!-- HARDWARE -->
          <div id="csg-hardware" class="tab-panel hidden">
            <ul class="list-disc pl-5 space-y-2 text-sm text-neutral-700 dark:text-neutral-300">
              <li><strong>Electrodes:</strong> 12 textile CSGs: 4 (20x20cm) torso pads and 8 (20x8cm) arm pads with ‚â•4&nbsp;cm spacing.</li>
              <li><strong>Garment:</strong> Loose-fitting shirt; electrodes sewn under fabric; sanitized between sessions.</li>
              <li><strong>Electronics:</strong> 3 FDC2214EVM capacitive sensors; Battery-powered, low-voltage, insulated; measures capacitance only.</li>
              <li><strong>Data:</strong> Timestamped capacitance streams (Baseline, Raw Signal, SNR) to a laptop for synchronization and labeling.</li>
            </ul>
          </div>
    
          <!-- STUDY DESIGN -->
          <!-- STUDY DESIGN -->
          <!-- STUDY DESIGN -->
          <div id="csg-study" class="tab-panel hidden">
            <div class="grid md:grid-cols-2 gap-4 text-sm text-neutral-700 dark:text-neutral-300">
              <div>
                <h4 class="font-medium mb-1">Participants & Sessions</h4>
                <ul class="list-disc pl-5 space-y-1">
                  <li>N=24 adults (12 dyads), 18‚Äì45 years.</li>
                  <li>~75 min session: consent (10), fitting (5), tasks (45‚Äì50), survey/debrief (10).</li>
                  <li>Baseline solo movement for calibration.</li>
                </ul>
              </div>
              <div>
                <h4 class="font-medium mb-1">Labels & Safety</h4>
                <ul class="list-disc pl-5 space-y-1">
                  <li>Synchronized overhead video + event markers for episode labeling.</li>
                  <li>Counterbalanced task order; 2‚Äì4 trials/task, 1‚Äì3 min each.</li>
                  <li>Light-contact only; pause/stop anytime.</li>
                </ul>
              </div>
            </div>
          
            <!-- Explanation -->
            <p class="mt-5 text-sm text-neutral-700 dark:text-neutral-300">
              The following table lists the dyadic social interaction tasks, organized by five categories of interaction. 
              Each task was designed to be brief (1‚Äì3 minutes) and involve light, safe contact.
            </p>
          
            <!-- Tasks by Category -->
            <div class="mt-3 overflow-x-auto rounded-xl ring-1 ring-neutral-200 dark:ring-neutral-800">
              <table class="min-w-[720px] w-full border-collapse text-sm">
                <caption class="sr-only">Dyadic social interaction tasks by category</caption>
                <thead class="bg-neutral-50 dark:bg-neutral-900">
                  <tr>
                    <th class="px-4 py-3 text-left font-semibold border-b border-neutral-200 dark:border-neutral-800">Exchange</th>
                    <th class="px-4 py-3 text-left font-semibold border-b border-neutral-200 dark:border-neutral-800">Competition</th>
                    <th class="px-4 py-3 text-left font-semibold border-b border-neutral-200 dark:border-neutral-800">Conflict</th>
                    <th class="px-4 py-3 text-left font-semibold border-b border-neutral-200 dark:border-neutral-800">Cooperation</th>
                    <th class="px-4 py-3 text-left font-semibold border-b border-neutral-200 dark:border-neutral-800">Accommodation</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Handshake</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Rock-Paper-Scissors</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Pushing (Gentle)</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Jointly Assemble</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Hug</td>
                  </tr>
                  <tr>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Exchanging Object</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Pick Tissue First</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Block Your Way</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Carry Box Together</td>
                    <td class="px-4 py-3 border-b border-neutral-200 dark:border-neutral-800">Support to Walk</td>
                  </tr>
                  <tr>
                    <td class="px-4 py-3">Chat (10 s)</td>
                    <td class="px-4 py-3">Towel Tugging</td>
                    <td class="px-4 py-3">Step on Foot + Step Away</td>
                    <td class="px-4 py-3">Two-Person Tote Loading</td>
                    <td class="px-4 py-3">Patting on the Shoulder</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>


    
          <!-- Footer actions -->
          <div class="pt-2 border-t border-neutral-200 dark:border-neutral-800 flex items-center justify-end">
            <button class="mt-3 inline-flex items-center gap-2 bg-brand-600 text-white px-4 py-2 rounded-xl hover:bg-brand-700"
                    data-modal-close data-autofocus>Close</button>
          </div>
        </section>
      </div>
    </div>

    
    <!-- Modal: Text2IMU -->
    <div id="modal-text2imu"
         class="fixed inset-0 z-[60] hidden items-start md:items-center justify-center p-0 md:p-6 overscroll-contain"
         role="dialog" aria-modal="true" aria-labelledby="modal-csg-title">
      <!-- Backdrop -->
      <div class="absolute inset-0 bg-black/60 backdrop-blur-sm" data-modal-close></div>
    
      <!-- Panel -->
      <div class="relative w-full md:max-w-4xl max-h-[90vh] grid grid-rows-[auto,1fr] overflow-hidden
                  rounded-2xl bg-white dark:bg-neutral-950 border border-neutral-200 dark:border-neutral-800 shadow-mellow">
    
        <!-- Header -->
        <div class="sticky top-0 z-10 bg-white dark:bg-neutral-950 border-b border-neutral-200 dark:border-neutral-800">
          <div class="flex items-start justify-between gap-4 p-4">
            <div>
              <h3 id="modal-vp-title" class="text-lg md:text-xl font-semibold">
                Generating Realistic Inertial Sensor Data from Natural-Language Activity Descriptions
              </h3>
              <div class="mt-1 flex flex-wrap gap-2 text-xs">
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">HCI</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">Wearables</span>
                <span class="px-2 py-1 rounded-full bg-neutral-100 dark:bg-neutral-900">LLMs</span>
              </div>
            </div>
            <button class="rounded-lg p-2 hover:bg-neutral-100 dark:hover:bg-neutral-900" data-modal-close aria-label="Close">‚úï</button>
          </div>

          <div class="w-full flex justify-center">
            <div class="w-full max-w-[400px] md:max-w-[400px]">
              <img
                src="assets/Text2IMU-poster.png" 
                alt="Text2IMU project cover"
                width="1000" height="500"
                class="block w-full h-auto rounded-xl ring-1 ring-neutral-800/50 object-contain"
                loading="lazy" decoding="async">
            </div>
          </div>
    
          <!-- Tabs -->
          <nav class="flex gap-2 overflow-x-auto p-3 border-t border-neutral-200 dark:border-neutral-800 text-sm">
            <button class="tab-btn px-3 py-1.5 rounded-xl bg-neutral-100 dark:bg-neutral-900" data-tab="t2i-overview">Overview</button>
            <button class="tab-btn px-3 py-1.5 rounded-xl hover:bg-neutral-100 dark:hover:bg-neutral-900" data-tab="t2i-hardware">Pipeline</button>

        
          </nav>
        </div>


    
        <!-- Body (scrollable) -->
        <section class="p-5 overflow-y-auto max-h-[calc(90vh-14rem)] space-y-8">
    
          <!-- OVERVIEW -->
          <div id="t2i-overview" class="tab-panel">
            <p class="text-neutral-700 dark:text-neutral-300 leading-relaxed">
              Human Activity Recognition (HAR) research relies heavily on inertial measurement unit (IMU) data, yet collecting large, diverse, and labeled datasets remains costly and labor-intensive. The scarcity of publicly available IMU datasets limits reproducibility, scalability, and exploration of novel activity scenarios. To address this challenge, we present Text2IMU: Generating Realistic Inertial Sensor Data from Natural-Language Activity Descriptions. Text2IMU converts short textual activity prompts into realistic IMU signals through a multi-stage process: (1) translating natural-language descriptions into 3D motion sequences using a text-to-motion model, (2) mapping motion trajectories into joint kinematics, and (3) simulating IMU signals such as accelerometer and gyroscope outputs, calibrated to reflect real-world noise characteristics. This framework enables the generation of flexible, on-demand sensor data without requiring physical recordings. By augmenting existing datasets and creating synthetic benchmarks, Text2IMU provides an effective pathway to overcome data scarcity in HAR and supports the development of more robust recognition models.
            </p>
          </div>
    
          <!-- PIPELINE -->
          <div id="t2i-pipeline" class="tab-panel hidden">
            <ol class="list-decimal pl-5 space-y-2 text-neutral-700 dark:text-neutral-300 text-sm">
              <li><strong>Prompt ‚Üí Motion:</strong> encode text; decode 3D human motion (global/root + joints).</li>
              <li><strong>Motion ‚Üí Kinematics:</strong> compute joint rotations/translations (e.g., quaternions, Euler).</li>
              <li><strong>Kinematics ‚Üí IMU:</strong> place virtual sensors; derive linear acceleration & angular velocity; add sensor noise/bias; export synchronized streams.</li>
            </ol>
            <div class="mt-4 grid sm:grid-cols-3 gap-3 text-xs">
              <div class="rounded-xl border border-neutral-200 dark:border-neutral-800 p-3">
                <p class="font-semibold">Inputs</p>
                <p class="text-neutral-500 dark:text-neutral-400">Short prompt (‚Äújump forward‚Äù), sensor layout.</p>
              </div>
              <div class="rounded-xl border border-neutral-200 dark:border-neutral-800 p-3">
                <p class="font-semibold">Outputs</p>
                <p class="text-neutral-500 dark:text-neutral-400">CSV/JSON: accel (m/s¬≤), gyro (rad/s), timestamps.</p>
              </div>
              <div class="rounded-xl border border-neutral-200 dark:border-neutral-800 p-3">
                <p class="font-semibold">Use Cases</p>
                <p class="text-neutral-500 dark:text-neutral-400">Data augmentation, stress tests, rare scenarios.</p>
              </div>
            </div>
          </div>

    
          <!-- Footer actions -->
          <div class="pt-2 border-t border-neutral-200 dark:border-neutral-800 flex items-center justify-end">
            <button class="mt-3 inline-flex items-center gap-2 bg-brand-600 text-white px-4 py-2 rounded-xl hover:bg-brand-700"
                    data-modal-close data-autofocus>Close</button>
          </div>
        </section>
      </div>
    </div>



  </main>

  <!-- Footer -->
  <footer class="py-10 border-t border-neutral-200/70 dark:border-neutral-800 text-sm">
    <div class="max-w-6xl mx-auto px-4 flex flex-col md:flex-row items-center justify-between gap-4">
      <p>¬© <span id="year"></span> Mohammed Saferi Rahman. All rights reserved.</p>
      <div class="flex items-center gap-4">
        <a href="#home" class="hover:text-brand-600 dark:hover:text-brand-400">Back to top ‚Üë</a>
      </div>
    </div>
  </footer>

  <!-- Utilities -->
  <script>
    // Year
    document.getElementById('year').textContent = new Date().getFullYear();

    // Theme toggle with persistence + update browser chrome color
    const metaTheme = document.getElementById('metaThemeColor');
    const applyThemeColor = () => {
      if (document.documentElement.classList.contains('dark')) {
        if (metaTheme) metaTheme.content = '#0a0a0a';
      } else {
        if (metaTheme) metaTheme.content = '#ffffff';
      }
    };
    applyThemeColor();

    document.getElementById('themeToggle').addEventListener('click', () => {
      const html = document.documentElement;
      html.classList.toggle('dark');
      const isDark = html.classList.contains('dark');
      localStorage.setItem('theme', isDark ? 'dark' : 'light');
      applyThemeColor();
    });

    // Mobile menu
    const menuBtn = document.getElementById('menuBtn');
    const mobileMenu = document.getElementById('mobileMenu');
    menuBtn.addEventListener('click', () => mobileMenu.classList.toggle('hidden'));
  </script>

  <!-- JSON-LD (schema.org Person) -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Mohammed Saferi Rahman",
    "affiliation": {
      "@type": "CollegeOrUniversity",
      "name": "Florida State University"
    },
    "jobTitle": "PhD Student",
    "description": "Research in HCI and Ubiquitous Computing.",
    "url": "https://<username>.github.io/",
    "sameAs": [
      "https://github.com/<username>",
      "https://scholar.google.com/citations?user=<id>",
      "https://www.linkedin.com/in/<username>"
    ]
  }
  </script>
</body>
</html>
